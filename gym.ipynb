{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Box\n",
    "from typing import Any, SupportsFloat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdt\n",
    "import random\n",
    "\n",
    "from stable_baselines3 import A2C\n",
    "\n",
    "from grid import Microgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/orventro/.local/lib/python3.10/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0. , 0.2, 1. , 0. , 0. ]), {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet('./data/power_price.parquet')\n",
    "df = df.dropna()\n",
    "days = df['time'].dt.date.unique()\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for day in days:\n",
    "    part = df[df['time'].dt.date == day]\n",
    "    if len(part) == 288:\n",
    "        dataset.append({'power' : part['power'].to_numpy(),\n",
    "                        'price' : part['price'].to_numpy()})\n",
    "\n",
    "env = Microgrid()\n",
    "env.reset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = A2C('MlpPolicy', env, verbose=0)\n",
    "m = model.learn(total_timesteps=28800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleAlgo(state):\n",
    "    t, batt, price, sol, hydro = state\n",
    "    return np.array([10, 1 - price])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1, score_rand 36.84997893683129, score_model 42.07986713612437, score_algo 17.825047920406288\n",
      "Episode 2, score_rand 49.06437652582723, score_model 64.5666877982593, score_algo 31.217656503843727\n",
      "Episode 3, score_rand 45.91596470935793, score_model 60.0210271217841, score_algo 44.47793877213418\n",
      "Episode 4, score_rand 42.2657585234344, score_model 56.406177506913785, score_algo 53.86313023287289\n",
      "Episode 5, score_rand 45.01136508275018, score_model 67.31955324628302, score_algo 72.598650573009\n",
      "Episode 6, score_rand 227.27283980232917, score_model 299.07693159534836, score_algo 590.6147747767817\n",
      "Episode 7, score_rand 39.45224514447795, score_model 53.8215437979712, score_algo 46.32821986443562\n",
      "Episode 8, score_rand 34.62737732656973, score_model 72.62580479634846, score_algo 88.79857199957699\n",
      "Episode 9, score_rand 55.87064318485029, score_model 78.19725611445702, score_algo 82.41103608310574\n",
      "Episode 10, score_rand 63.30731426578388, score_model 94.24801172127533, score_algo 85.25487152064461\n"
     ]
    }
   ],
   "source": [
    "episodes = 10\n",
    "\n",
    "for ep in range(episodes):\n",
    "    seed = random.randint(0, 1e9)\n",
    "\n",
    "    state, info = env.reset(seed=seed)\n",
    "    done = False\n",
    "    score_rand = 0\n",
    "    while not done:\n",
    "        action = env.action_space.sample()\n",
    "        state, reward, done, trunc, info = env.step(action)\n",
    "        score_rand += reward\n",
    "    \n",
    "\n",
    "    state, info = env.reset(seed=seed)\n",
    "    done = False\n",
    "    score_model = 0\n",
    "    while not done:\n",
    "        action, state = model.predict(state)\n",
    "        state, reward, done, trunc, info = env.step(action)\n",
    "        score_model += reward\n",
    "    \n",
    "    state, info = env.reset(seed=seed)\n",
    "    done = False\n",
    "    score_algo = 0\n",
    "    while not done:\n",
    "        action = simpleAlgo(state)\n",
    "        state, reward, done, trunc, info = env.step(action)\n",
    "        score_algo += reward\n",
    "    print(f'Episode {ep+1}, score_rand {score_rand}, score_model {score_model}, score_algo {score_algo}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "868f397eb618ffbee5069d46a74f1311d7f755ffa6d7c2ea597f71a940bcd474"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
